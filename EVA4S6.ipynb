{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rg1ZVZ8xHEXI"
   },
   "source": [
    "# Installing Packages\n",
    "The following packages need to be installed before running the code below\n",
    "- torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zMOoKk0OHEqe",
    "outputId": "8c91b8b9-6f9a-4473-e34a-2ad1d76847d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aO-7t1Y7-hV4"
   },
   "source": [
    "# Imports\n",
    "Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kH16rnZ7wt_"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-15c1c80d83c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OfOSzHr1GW2c"
   },
   "source": [
    "# Dataset Preparation and Loading\n",
    "The following steps are performed for preparing the dataset for the model.\n",
    "- Downloading the MNIST dataset\n",
    "- Visualizing the dataset and the data statistics\n",
    "- Defining data transformations\n",
    "- Splitting the dataset into train and validation set\n",
    "- Creating data loader for train and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ffnfhydPLQk5"
   },
   "source": [
    "## Data Visualization and Statistics\n",
    "Let's see how our data looks like and what are the mean and standard deviation values of the dataset. This information will help us decide the transformations that can be used on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "gaxNDurqLY4X",
    "outputId": "44a710da-34e7-4448-bf12-42cd717c58af"
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "sample_data = datasets.MNIST('./data', train=True, download=True).data\n",
    "\n",
    "# Setti32ng the values in the data to be within the range [0, 1]\n",
    "sample_data = sample_data.numpy() / 255\n",
    "\n",
    "# Display some data statistics\n",
    "print('Data Statistics:')\n",
    "print(' - Data Shape:', sample_data.shape)\n",
    "print(' - min:', np.min(sample_data))\n",
    "print(' - max:', np.max(sample_data))\n",
    "print(' - mean: %.4f' % np.mean(sample_data))\n",
    "print(' - std: %.4f' % np.std(sample_data))\n",
    "print(' - var: %.4f\\n' % np.var(sample_data))\n",
    "\n",
    "# Visualize a sample from the data\n",
    "plt.imshow(sample_data[0], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7tClldqIR0zA"
   },
   "source": [
    "Let's view some more images. This will help in getting any ideas for data augmentation later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "k7TxQifTMYLC",
    "outputId": "5859b4c7-d82e-44a7-d3c3-731056e571fc"
   },
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_data[index], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "grHT765783fO"
   },
   "source": [
    "## Data Transformations\n",
    "\n",
    "The following transformations will be used\n",
    "- ToTensor\n",
    "- Normalize\n",
    "- RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSpchiU79LnW"
   },
   "outputs": [],
   "source": [
    "# Train phase transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    # Rotate image by 7 degrees\n",
    "    transforms.RandomRotation((-6.0, 6.0), fill=(1,)),\n",
    "\n",
    "    # convert the data to torch.FloatTensor with values within the range [0.0 ,1.0]\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # normalize the data with mean and standard deviation\n",
    "    # these values were obtained from the data statistics above\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Validation phase transformations\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1g-Wd56S-3tg"
   },
   "source": [
    "## Train Data and Validation Data Split\n",
    "The data is downloaded and split into two sets: train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHJkLW3H_DZb"
   },
   "outputs": [],
   "source": [
    "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
    "val = datasets.MNIST('./data', train=False, download=True, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFcWRAeY_MsB"
   },
   "source": [
    "## Training and Validation Dataloaders\n",
    "This is the final step in data preparation. It sets the dataloader arguments and then creates the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uT2fytsOGNV2",
    "outputId": "79e9e07b-45b7-42ff-8ace-0432848176c1"
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA Available?', cuda)\n",
    "\n",
    "# For reproducibility of results\n",
    "torch.manual_seed(SEED)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# dataloader arguments\n",
    "dataloader_args = dict(shuffle=True, batch_size=64, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=32)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# validation dataloader\n",
    "val_loader = torch.utils.data.DataLoader(val, **dataloader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSeDIqBq-6pC"
   },
   "source": [
    "# Model Architecture\n",
    "Designing the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-fLk9QHJGFt"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" This function instantiates all the model layers \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        dropout_rate = 0.01\n",
    "\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )  # Input: 28x28x1 | Output: 26x26x8 | RF: 3x3\n",
    "\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )  # Input: 26x26x8 | Output: 24x24x8 | RF: 5x5\n",
    "\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )  # Input: 24x24x8 | Output: 22x22x16 | RF: 7x7\n",
    "\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )  # Input: 22x22x16 | Output: 20x20x16 | RF: 9x9\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Input: 20x20x16 | Output: 10x10x16 | RF: 10x10\n",
    "\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )  # Input: 10x10x16 | Output: 8x8x16 | RF: 14x14\n",
    "\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )  # Input: 8x8x16 | Output: 6x6x16 | RF: 18x18\n",
    "\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )  # Input: 6x6x16 | Output: 6x6x10 | RF: 18x18\n",
    "\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )  # Input: 6x6x10 | Output: 1x1x10 | RF: 28x28\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" This function defines the network structure \"\"\"\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-yrNmc72D5yE"
   },
   "source": [
    "## Model Parameters\n",
    "Let's see the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "colab_type": "code",
    "id": "FJGvqMnvFvLb",
    "outputId": "bdaee112-7be3-4046-d042-6de5acb5efe6"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcyKrcQEGcdp"
   },
   "source": [
    "# Model Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2VZKTTi_FJx"
   },
   "source": [
    "Function for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1N1CK2-eF1Y7"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, l1_factor):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        # Get samples\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set gradients to zero before starting backpropagation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Predict output\n",
    "        y_pred = model(data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.nll_loss(y_pred, target)\n",
    "        if l1_factor > 0:  # Apply L1 regularization\n",
    "            l1_criteria = nn.L1Loss(size_average=False)\n",
    "            regularizer_loss = 0\n",
    "            for parameter in model.parameters():\n",
    "                regularizer_loss += l1_criteria(parameter, torch.zeros_like(parameter))\n",
    "            loss += l1_factor * regularizer_loss\n",
    "\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update Progress Bar\n",
    "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        processed += len(data)\n",
    "        pbar.set_description(desc=f'Loss={loss.item():0.2f} Batch_ID={batch_idx} Accuracy={(100 * correct / processed):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EC1kZAnj_NbJ"
   },
   "source": [
    "Function for model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKquSvZP_TQp"
   },
   "outputs": [],
   "source": [
    "def val(model, device, val_loader, losses, accuracies, incorrect_samples):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            img_batch = data  # This is done to keep data in CPU\n",
    "            data, target = data.to(device), target.to(device)  # Get samples\n",
    "            output = model(data)  # Get trained model output\n",
    "            val_loss += F.nll_loss(output, target, reduction='sum').item()  # Sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "            result = pred.eq(target.view_as(pred))\n",
    "\n",
    "            # Save incorrect samples\n",
    "            if len(incorrect_samples) < 25:\n",
    "                for i in range(val_loader.batch_size):\n",
    "                    if not list(result)[i]:\n",
    "                        incorrect_samples.append({\n",
    "                            'prediction': list(pred)[i],\n",
    "                            'label': list(target.view_as(pred))[i],\n",
    "                            'image': list(img_batch)[i]\n",
    "                        })\n",
    "\n",
    "            correct += result.sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    losses.append(val_loss)\n",
    "    accuracies.append(100. * correct / len(val_loader.dataset))\n",
    "\n",
    "    print(f'\\nValidation set: Average loss: {val_loss:.4f}, Accuracy: {correct}/{len(val_loader.dataset)} ({accuracies[-1]:.2f}%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpxs5bnkARdS"
   },
   "source": [
    "Function for model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vddk65TZGeZx"
   },
   "outputs": [],
   "source": [
    "def run_model(l1=0.0, l2=0.0):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    incorrect_samples = []\n",
    "    \n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=l2)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.15)\n",
    "    epochs = 40\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f'Epoch {epoch}:')\n",
    "        train(model, device, train_loader, optimizer, epoch, l1)\n",
    "        scheduler.step()\n",
    "        val(model, device, val_loader, losses, accuracies, incorrect_samples)\n",
    "    \n",
    "    return losses, accuracies, incorrect_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBkas4N_AsM3"
   },
   "source": [
    "### Without L1 and L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XUGDkH4CA88P",
    "outputId": "5fa51f48-477d-444f-e3c6-3939288b955e"
   },
   "outputs": [],
   "source": [
    "loss, accuracy, incorrect_pred = run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DdhqfytZAyTu"
   },
   "source": [
    "### With L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zr8qI6b5A8a6",
    "outputId": "50ad7683-e743-457e-fad7-caf257896bbf"
   },
   "outputs": [],
   "source": [
    "l1_loss, l1_accuracy, incorrect_pred_l1 = run_model(l1=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTuSMYF8A2Od"
   },
   "source": [
    "### With L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B4RDXDWhA7zA",
    "outputId": "4764dc70-74cc-4691-e3c5-3098049ff70e"
   },
   "outputs": [],
   "source": [
    "l2_loss, l2_accuracy, incorrect_pred_l2 = run_model(l2=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7De7ZyYVA4IO"
   },
   "source": [
    "### With L1 and L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5-HS1MGaA7JG",
    "outputId": "566e4d65-f121-4aa4-9313-1709bb137651"
   },
   "outputs": [],
   "source": [
    "l1_l2_loss, l1_l2_accuracy, incorrect_pred_l1_l2 = run_model(l1=0.001, l2=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2o99Jq1XTdo-"
   },
   "source": [
    "## Plotting Results\n",
    "Plotting changes in validation loss and accuracy obtained during model training in the following scenarios:\n",
    "1. Without L1 and L2 regularization\n",
    "2. With L1 regularization\n",
    "3. With L2 regularization\n",
    "4. With L1 and L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0X1Y72EbGgpr"
   },
   "outputs": [],
   "source": [
    "def plot_metric(plain, l1, l2, l1_l2, metric):\n",
    "    # Initialize a figure\n",
    "    fig = plt.figure(figsize=(13, 11))\n",
    "\n",
    "    # Plot values\n",
    "    plain_plt, = plt.plot(plain)\n",
    "    l1_plt, = plt.plot(l1)\n",
    "    l2_plt, = plt.plot(l2)\n",
    "    l1_l2_plt, = plt.plot(l1_l2)\n",
    "\n",
    "    # Set plot title\n",
    "    plt.title(f'Validation {metric}')\n",
    "\n",
    "    # Label axes\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "\n",
    "    # Set legend\n",
    "    location = 'upper' if metric == 'Loss' else 'lower'\n",
    "    plt.legend(\n",
    "        (plain_plt, l1_plt, l2_plt, l1_l2_plt),\n",
    "        ('Plain', 'L1', 'L2', 'L1 + L2'),\n",
    "        loc=f'{location} right',\n",
    "        shadow=True,\n",
    "        prop={'size': 20}\n",
    "    )\n",
    "\n",
    "    # Save plot\n",
    "    fig.savefig(f'{metric.lower()}_change.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvkqQXw-2buM"
   },
   "source": [
    "Plot changes in validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "xfpsO9CV2bVp",
    "outputId": "200bbfea-cef7-41cf-8a2d-d0b0b07e7f44"
   },
   "outputs": [],
   "source": [
    "plot_metric(loss, l1_loss, l2_loss, l1_l2_loss, 'Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSctNrPG2afY"
   },
   "source": [
    "Plot changes in validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "IflmdH8x2oNt",
    "outputId": "a774f883-eb62-4e87-e40a-3569773b28db"
   },
   "outputs": [],
   "source": [
    "plot_metric(accuracy, l1_accuracy, l2_accuracy, l1_l2_accuracy, 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "frMHF1KQt0Ff"
   },
   "source": [
    "## Display Results\n",
    "\n",
    "Display 25 misclassified images for the following trained models:\n",
    "1. Without L1 and L2 regularization\n",
    "2. With L1 regularization\n",
    "3. With L2 regularization\n",
    "4. With L1 and L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NXcw_YvVk0J"
   },
   "outputs": [],
   "source": [
    "def save_and_show_result(data, metric):\n",
    "    # Initialize plot\n",
    "    row_count = -1\n",
    "    fig, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for idx, result in enumerate(data):\n",
    "\n",
    "        # If 25 samples have been stored, break out of loop\n",
    "        if idx > 24:\n",
    "            break\n",
    "        \n",
    "        label = result['label'].item()\n",
    "        prediction = result['prediction'].item()\n",
    "\n",
    "        # Plot image\n",
    "        if idx % 5 == 0:\n",
    "            row_count += 1\n",
    "        axs[row_count][idx % 5].axis('off')\n",
    "        axs[row_count][idx % 5].set_title(f'Label: {label}\\nPrediction: {prediction}')\n",
    "        axs[row_count][idx % 5].imshow(result['image'][0], cmap='gray_r')\n",
    "\n",
    "        # Save each image individually in labelled format\n",
    "        extent = axs[row_count][idx % 5].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig(f'{metric}/labelled/{metric}_{idx + 1}.png', bbox_inches=extent.expanded(1.1, 1.5))\n",
    "    \n",
    "    # Save image\n",
    "    fig.savefig(f'{metric}/{metric}_incorrect_predictions.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NJXL822Mqw9"
   },
   "source": [
    "### With L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yBTSiToQNKDw",
    "outputId": "ae497e5e-1d3c-4bf9-d55e-d9396487688a"
   },
   "outputs": [],
   "source": [
    "# Making directories\n",
    "!mkdir l1\n",
    "!mkdir l1/labelled\n",
    "\n",
    "save_and_show_result(incorrect_pred_l1, 'l1')\n",
    "\n",
    "# For downloading the results\n",
    "!zip -r l1.zip l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyr3wlwhNnuG"
   },
   "source": [
    "### With L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GPzjW4d8NfvA",
    "outputId": "5b9e75a8-ed09-4419-a60d-2360fdabf329"
   },
   "outputs": [],
   "source": [
    "# Making directories\n",
    "!mkdir l2\n",
    "!mkdir l2/labelled\n",
    "\n",
    "save_and_show_result(incorrect_pred_l2, 'l2')\n",
    "\n",
    "# For downloading the results\n",
    "!zip -r l2.zip l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gplzWSUSoSbQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EVA4S6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
